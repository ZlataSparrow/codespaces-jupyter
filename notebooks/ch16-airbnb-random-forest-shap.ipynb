{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepared for Gabor's Data Analysis\n",
    "\n",
    "### Data Analysis for Business, Economics, and Policy\n",
    "by Gabor Bekes and Gabor Kezdi\n",
    " \n",
    "Cambridge University Press 2021\n",
    "\n",
    "**[gabors-data-analysis.com ](https://gabors-data-analysis.com/)**\n",
    "\n",
    " License: Free to share, modify and use for educational purposes. \n",
    " Not to be used for commercial purposes.\n",
    "\n",
    "### Chapter 16\n",
    "**CH16A Predicting apartment prices with random forest**\n",
    "\n",
    "using the airbnb dataset\n",
    "\n",
    "version 0.92 2021-07-05\n",
    "\n",
    "\n",
    "### NOTE: THIS IS NEW MATERIAL, NOT YET IN THE TEXTBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from patsy import dmatrices\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.inspection import partial_dependence, permutation_importance\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART I\n",
    "### Loading and preparing data \n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! make sure you have run ch16-airbnb-prepare-london.ipynb before\n",
    "area = \"london\"\n",
    "data = pd.read_csv(\"/workspaces/codespaces-jupyter/data/airbnb_hackney_workfile_adj.csv\")\n",
    "data = data.loc[data.price.notna(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_missing_values(df):\n",
    "    return df.isna().sum()[df.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "usd_cleaning_fee           1727\n",
       "p_host_response_rate       1526\n",
       "n_bathrooms                   9\n",
       "n_review_scores_rating     1423\n",
       "n_reviews_per_month        1349\n",
       "n_beds                       12\n",
       "n_days_since               1349\n",
       "ln_beds                      12\n",
       "f_bathroom                    9\n",
       "f_number_of_reviews           1\n",
       "ln_days_since              1350\n",
       "ln_days_since2             1350\n",
       "ln_days_since3             1350\n",
       "n_days_since2              1349\n",
       "n_days_since3              1349\n",
       "ln_review_scores_rating    1423\n",
       "f_minimum_nights              1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_missing_values(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample definition and preparation ---------------------------------------\n",
    "# We focus on normal apartments, n<8\n",
    "data = data.loc[lambda x: x[\"n_accommodates\"] < 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy a variable - purpose later, see at variable importance\n",
    "data = data.assign(n_accommodates_copy=data.n_accommodates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic descr stat -------------------------------------------\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.f_room_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.f_property_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.f_number_of_reviews.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and holdout samples -------------------------------------------\n",
    "# train is where we do it all, incl CV\n",
    "\n",
    "# First pick a smaller than usual training set so that models run faster and check if works\n",
    "# If works, start anew without these two lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_holdout = train_test_split(data, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.shape, data_holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Variables inc neighnourhood\n",
    "basic_vars = [\n",
    "    \"n_accommodates\",\n",
    "    \"n_beds\",\n",
    "    \"n_days_since\",\n",
    "    \"f_property_type\",\n",
    "    \"f_room_type\",\n",
    "    \"f_bathroom\",\n",
    "    \"f_cancellation_policy\",\n",
    "    \"f_bed_type\",\n",
    "    \"f_neighbourhood_cleansed\",\n",
    "]\n",
    "\n",
    "# reviews\n",
    "reviews = [\n",
    "    \"n_number_of_reviews\",\n",
    "    \"flag_n_number_of_reviews\",\n",
    "    \"n_review_scores_rating\",\n",
    "    \"flag_review_scores_rating\",\n",
    "]\n",
    "\n",
    "# Dummy variables\n",
    "amenities = [col for col in data if col.startswith(\"d_\")]\n",
    "\n",
    "# interactions for the LASSO\n",
    "# from ch14\n",
    "X1 = [\n",
    "    \"n_accommodates:f_property_type\",\n",
    "    \"f_room_type:f_property_type\",\n",
    "    \"f_room_type:d_familykidfriendly\",\n",
    "    \"d_airconditioning:f_property_type\",\n",
    "    \"d_cats:f_property_type\",\n",
    "    \"d_dogs:f_property_type\",\n",
    "]\n",
    "# with boroughs\n",
    "X2 = [\n",
    "    \"f_property_type:f_neighbourhood_cleansed\",\n",
    "    \"f_room_type:f_neighbourhood_cleansed\",\n",
    "    \"n_accommodates:f_neighbourhood_cleansed\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_1 = basic_vars\n",
    "predictors_2 = basic_vars + reviews + amenities\n",
    "predictors_E = basic_vars + reviews + amenities + X1 + X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [col for col in predictors_2 if col.startswith(\"f_\")]\n",
    "numerical_columns = [col for col in predictors_2 if col not in categorical_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sklearn preprocessor for encoding categorical variables to dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"cat\", OneHotEncoder(), categorical_columns),\n",
    "        (\"num\", \"passthrough\", numerical_columns),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessor.fit_transform(data_train[predictors_2])\n",
    "X = pd.DataFrame(X, columns=preprocessor.get_feature_names_out())\n",
    "y = data_train[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART II\n",
    "### RANDOM FORESTS \n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** n_estimators=500 in the R code.\n",
    "\n",
    "Here, we set it to 30 because the model runs mutch faster, and this does not change the results substantively here – however in other cases might."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: set number of cores you want to run models\n",
    "ncores = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(\n",
    "    random_state=42,\n",
    "    criterion=\"squared_error\",\n",
    "    n_estimators=30,\n",
    "    oob_score=True,\n",
    "    n_jobs=ncores,\n",
    ")\n",
    "\n",
    "tune_grid = {\"max_features\": [5, 7, 9], \"min_samples_split\": [6, 11]}\n",
    "\n",
    "rf_random = GridSearchCV(\n",
    "    rfr, tune_grid, cv=5, scoring=\"neg_root_mean_squared_error\", verbose=3\n",
    ")\n",
    "\n",
    "rf_model_1 = rf_random.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(\n",
    "    random_state=42,\n",
    "    criterion=\"squared_error\",\n",
    "    n_estimators=30,\n",
    "    oob_score=True,\n",
    "    n_jobs=ncores,\n",
    ")\n",
    "\n",
    "tune_grid = {\n",
    "    \"max_features\": [8, 10, 12],\n",
    "    \"min_samples_split\": [6, 11, 16],\n",
    "}\n",
    "\n",
    "rf_random = GridSearchCV(\n",
    "    rfr,\n",
    "    tune_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose=3,\n",
    ")\n",
    "\n",
    "rf_model_2 = rf_random.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 16.1 Random forest RMSE by tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pd.DataFrame(rf_model_2.cv_results_)[\n",
    "        [\"param_max_features\", \"param_min_samples_split\", \"mean_test_score\"]\n",
    "    ]\n",
    "    .assign(\n",
    "        mean_test_score=lambda x: x[\"mean_test_score\"] * -1,\n",
    "        Variables=lambda x: x[\"param_max_features\"],\n",
    "        Min_nodes=lambda x: x[\"param_min_samples_split\"] - 1,\n",
    "    )\n",
    "    .pivot(index=\"Min_nodes\", columns=\"Variables\", values=\"mean_test_score\")\n",
    "    .round(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"Min vars\": [\n",
    "            rf_model_1.best_estimator_.max_features,\n",
    "            rf_model_2.best_estimator_.max_features,\n",
    "        ],\n",
    "        \"Min nodes\": [\n",
    "            rf_model_1.best_estimator_.min_samples_split - 1,\n",
    "            rf_model_2.best_estimator_.min_samples_split - 1,\n",
    "        ],\n",
    "    },\n",
    "    [\"Model A\", \"Model B\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_1_rmse = rf_model_1.cv_results_[\"mean_test_score\"].max() * -1\n",
    "rf_model_2_rmse = rf_model_2.cv_results_[\"mean_test_score\"].max() * -1\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\"RMSE\": [rf_model_1_rmse, rf_model_2_rmse]}, [\"Model A\", \"Model B\"]\n",
    ").round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART III\n",
    "### MODEL DIAGNOSTICS \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_2_var_imp_df = (\n",
    "    pd.DataFrame(\n",
    "        [rf_model_2.best_estimator_.feature_importances_, X.columns],\n",
    "        index=[\"imp\", \"varname\"],\n",
    "    )\n",
    "    .T.assign(\n",
    "        imp_percentage=lambda x: x[\"imp\"] / x[\"imp\"].sum(),\n",
    "        varname=lambda x: x[\"varname\"]\n",
    "        .str.replace(\"cat__f_room_type_\", \"Room type:\", regex=False)\n",
    "        .str.replace(\"cat__f_neighbourhood_cleansed_\", \"Borough:\", regex=False)\n",
    "        .str.replace(\"cat__f_cancellation_policy_\", \"Cancelation policy:\", regex=False)\n",
    "        .str.replace(\"cat__f_bed_type_\", \"Bed type:\", regex=False)\n",
    "        .str.replace(\"cat_f_property_type_\", \"Property type:\", regex=False)\n",
    "        .str.replace(\"num__\", \"\", regex=False)\n",
    "        .str.replace(\"cat__f_bathroom_0\", \"No bathroom\")\n",
    "        .str.replace(\"cat__f_bathroom_1\", \"One bathroom\")\n",
    "        .str.replace(\"cat__f_bathroom_2\", \"More than 1 bathroom\"),\n",
    "    )\n",
    "    .sort_values(by=[\"imp\"], ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def da_variable_importance_plot(\n",
    "    data: pd.DataFrame,\n",
    "    x: str = \"imp_percentage\",\n",
    "    y: str = \"varname\",\n",
    "    title: str | None = None,\n",
    "):\n",
    "    data = data.sort_values(by=x, ascending=False)\n",
    "\n",
    "    sns.scatterplot(data=data, x=x, y=y, s=60)\n",
    "\n",
    "    # Add horizontal lines from 0 to imp_percentage\n",
    "    for _, row in data.iterrows():\n",
    "        plt.hlines(y=row[y], xmin=0, xmax=row[x], linewidth=2.5)\n",
    "\n",
    "    plt.xticks(np.arange(0, data[x].max(), 0.05))\n",
    "    plt.gca().xaxis.set_major_formatter(PercentFormatter(xmax=1, decimals=0))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Importance (Percent)\")\n",
    "    plt.ylabel(\"Variable Name\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) full varimp plot, above a cutoff**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0.013\n",
    "\n",
    "plot_df = rf_model_2_var_imp_df.loc[lambda x: x.imp > cutoff]\n",
    "da_variable_importance_plot(plot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) full varimp plot, top 10 only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = rf_model_2_var_imp_df.head(10)\n",
    "da_variable_importance_plot(plot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) grouped variable importance - keep binaries created off factors together\n",
    "\n",
    "First we do this by summing up the individual importances of factors - this is not correct, but it's in the first edition.\n",
    "\n",
    "Simply summing up the individual importances of each dummy could underestimate the importance of the qualitative variable. This occurs because omitting a single category might not significantly impact performance as the remaining correlated categories can still provide the model with the necessary information. \n",
    "\n",
    "To address this issue, we need to assess the impact of including the entire categorical variable, not just the individual dummies. We create a pipeline which first encodes the categorical variables into dummy variables, then trains the model on the encoded data. Finally, we can employ a model-agnostic feature importance technique on this entire pipeline to estimate the contribution of each variable. This way, one categorical variableis either included or not during the calculation of variable importances.\n",
    " \n",
    "Model-agnostic feature importance techniques are methods used to determine the importance of features in a model, regardless of the model type. These techniques work by assessing the impact of each feature on the model's predictions without relying on the internal workings of the model. One such technique is permutation feature importance, which randomly shuffles the values of variables and measures how much the fit of the prediction is decreased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_2_var_imp_df_grouped = (\n",
    "    pd.DataFrame(\n",
    "        [rf_model_2.best_estimator_.feature_importances_, X.columns],\n",
    "        index=[\"imp\", \"varname\"],\n",
    "    )\n",
    "    .T.assign(\n",
    "        varname=lambda x: np.where(\n",
    "            x[\"varname\"].str.contains(\"cat__\"),\n",
    "            x[\"varname\"].str.split(\"_\").str[:-1].str.join(\"_\"),\n",
    "            x[\"varname\"],\n",
    "        )\n",
    "    )\n",
    "    .assign(\n",
    "        varname=lambda x: x[\"varname\"].str.replace(\"cat__\", \"\").str.replace(\"num__\", \"\")\n",
    "    )\n",
    "    .groupby(\"varname\")[[\"imp\"]]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .assign(imp_percentage=lambda x: x[\"imp\"] / x[\"imp\"].sum())\n",
    "    .sort_values(by=[\"imp\"], ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = rf_model_2_var_imp_df_grouped.sort_values(by=[\"imp\"], ascending=False).head(\n",
    "    10\n",
    ")\n",
    "da_variable_importance_plot(\n",
    "    plot_df, title=\"Top 10 most important variable - factor variables summed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OneHotEncoding and training the RandomForest model in a pipeline and calculating permutation importance - second edition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"regressor\", rf_model_2.best_estimator_),  # put best model to pipeline\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_pipeline.fit(data_train[predictors_2], data_train.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a while\n",
    "result = permutation_importance(\n",
    "    rf_best_pipeline,\n",
    "    data_train[predictors_2],\n",
    "    data_train.price,\n",
    "    n_repeats=10,\n",
    "    random_state=45,\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_imp = pd.DataFrame(\n",
    "    [result.importances_mean, data_train[predictors_2].columns],\n",
    "    index=[\"imp\", \"varname\"],\n",
    ").T.assign(imp_percentage=lambda x: x[\"imp\"] / x[\"imp\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = grouped_imp.sort_values(by=[\"imp\"], ascending=False).head(10)\n",
    "da_variable_importance_plot(\n",
    "    plot_df,\n",
    "    title=\"Top 10 most important variable calculated with permutation importance\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Dependence Plots \n",
    "-------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_ylim_for_pdp(pdp_results: pd.DataFrame):\n",
    "    ymax = math.ceil(pdp_results[\"average\"].max() / 10) * 10\n",
    "    ymin = math.floor(pdp_results[\"average\"].min() / 10) * 10\n",
    "    plt.ylim(ymin, ymax)\n",
    "    plt.yticks(np.arange(ymin, ymax + 1, 10))\n",
    "\n",
    "\n",
    "def da_plot_partial_dependence(model, data: pd.DataFrame, variable: str, varlabel: str):\n",
    "\n",
    "    pdp_results = partial_dependence(model, data, [variable], kind=\"average\")\n",
    "\n",
    "    pdp_results = pd.DataFrame(\n",
    "        [pdp_results[\"average\"][0], pdp_results[\"values\"][0]],\n",
    "        index=[\"average\", \"values\"],\n",
    "    ).T\n",
    "\n",
    "    if pdp_results[\"values\"].dtype == \"object\":\n",
    "        linestyle = \"none\"\n",
    "    else:\n",
    "        linestyle = \"-\"\n",
    "\n",
    "    sns.pointplot(\n",
    "        data=pdp_results, x=\"values\", y=\"average\", scale=0.8, linestyle=linestyle\n",
    "    )\n",
    "    set_ylim_for_pdp(pdp_results)\n",
    "    plt.grid(axis=\"x\", linestyle=\"-\", alpha=0.7)\n",
    "    plt.xlabel(varlabel)\n",
    "    plt.ylabel(\"Predicted price\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_plot_partial_dependence(\n",
    "    rf_best_pipeline,\n",
    "    data_holdout[predictors_2],\n",
    "    \"n_accommodates\",\n",
    "    \"Accomodates (person)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_plot_partial_dependence(\n",
    "    rf_best_pipeline, data_holdout[predictors_2], \"f_room_type\", \"Room type\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsample performance: RMSE / mean(y) \n",
    "---------------------------------------\n",
    "NOTE  we do this on the holdout set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_holdout_w_prediction = data_holdout.assign(\n",
    "    predicted_price=rf_best_pipeline.predict(data_holdout[predictors_2])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create nice summary table of heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(groupby_obj):\n",
    "    return (\n",
    "        groupby_obj.apply(\n",
    "            lambda x: root_mean_squared_error(x.predicted_price, x.price),\n",
    "        )\n",
    "        .to_frame(name=\"rmse\")\n",
    "        .assign(mean_price=groupby_obj.apply(lambda x: np.mean(x.price)).values)\n",
    "        .assign(rmse_norm=lambda x: x.rmse / x.mean_price)\n",
    "        .round(2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cheaper or more expensive flats - not used in book\n",
    "grouped_object = data_holdout_w_prediction.assign(\n",
    "    is_low_size=lambda x: np.where(x.n_accommodates <= 3, \"small apt\", \"large apt\")\n",
    ").groupby(\"is_low_size\")\n",
    "accom_subset = calculate_rmse(grouped_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_object = data_holdout_w_prediction.loc[\n",
    "    lambda x: x.f_neighbourhood_cleansed.isin(\n",
    "        [\n",
    "            \"Westminster\",\n",
    "            \"Camden\",\n",
    "            \"Kensington and Chelsea\",\n",
    "            \"Tower Hamlets\",\n",
    "            \"Hackney\",\n",
    "            \"Newham\",\n",
    "        ]\n",
    "    )\n",
    "].groupby(\"f_neighbourhood_cleansed\")\n",
    "neightbourhood_subset = calculate_rmse(grouped_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_object = data_holdout_w_prediction.loc[\n",
    "    lambda x: x.f_property_type.isin([\"Apartment\", \"House\"])\n",
    "].groupby(\"f_property_type\")\n",
    "proptype_subset = calculate_rmse(grouped_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_holdout = (\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            root_mean_squared_error(\n",
    "                data_holdout_w_prediction.price,\n",
    "                data_holdout_w_prediction.predicted_price,\n",
    "            ),\n",
    "            data_holdout_w_prediction.price.mean(),\n",
    "        ],\n",
    "        index=[\"rmse\", \"mean_price\"],\n",
    "    )\n",
    "    .T.assign(rmse_norm=lambda x: x.rmse / x.mean_price)\n",
    "    .round(2)\n",
    ")\n",
    "all_holdout.index = [\"All\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_rows = pd.DataFrame(\n",
    "    None,\n",
    "    index=[\"Apartment size\", \"Type\", \"Borough\"],\n",
    "    columns=[\"rmse\", \"mean_price\", \"rmse_norm\"],\n",
    ").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 16.2 Performance across subsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        type_rows.iloc[[0]],\n",
    "        accom_subset,\n",
    "        type_rows.iloc[[1]],\n",
    "        proptype_subset,\n",
    "        type_rows.iloc[[2]],\n",
    "        neightbourhood_subset,\n",
    "        all_holdout,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_holdout = preprocessor.fit_transform(data_holdout[predictors_2])\n",
    "X_holdout = pd.DataFrame(X_holdout, columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate SHAP values for our best model\n",
    "\n",
    "**NOTE:** Again, we do this on the holdout set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(rf_best_pipeline[\"regressor\"].predict, X_holdout)\n",
    "shap_values = explainer(X_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beeswarm plot of SHAP values\n",
    "\n",
    "The beeswarm plot is designed to display an information-dense summary of how the top features in a dataset impact the model’s output. Each instance the given explanation is represented by a single dot on each feature row. The x position of the dot is determined by the SHAP value of that feature, and dots “pile up” along each feature row to show density. Color is used to display the original value of a feature. In the plot below we can see that Entire home/apt is the most important feature on average, and than Entire home/apt-s are more expensive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(\n",
    "    shap_values, max_display=15, color=plt.get_cmap(\"viridis_r\"), show=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can do the same with **SHAP values scaled log**. This might come handy, when the distribution of SHAP values are skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(\n",
    "    shap_values, max_display=15, log_scale=True, color=plt.get_cmap(\"viridis_r\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also display the **SHAP values in absolute**, on a beeswarm plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values.abs, color=color[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or on a barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanining predictions for a unit of observation (airbnb)\n",
    "\n",
    "Let's look at SHAP values for the third observation in the holdout set. \n",
    "\n",
    "- .values array contains the shap values\n",
    "- .base_values contains the expected value (intercept/constant in OLS terms)\n",
    "- .data contains the feature values for the observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Waterfall plot\n",
    "The waterfall plot shows how the sum of all the SHAP values equals the difference between the prediction $f(x)$ and the expected value $E[f(x)]$. Waterfall plots are designed to display explanations for individual predictions, so they expect a single row of an Explanation object as input. The bottom of a waterfall plot starts as the expected value of the model output, and then each row shows how the positive (red) or negative (blue) contribution of each feature moves the value from the expected model output over the background dataset to the model output for this prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same plot, but SHAP values for another observation below.\n",
    "\n",
    "Note, that for a same predictor (eg. f_room_type_Private room = 0) the SHAP values are different for the airbnb above (+5.29) and above (+6.88)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = categorical_columns + numerical_columns\n",
    "data_train_lime = data_train[feature_names].copy()\n",
    "data_holdout_lime = data_holdout[feature_names].copy()\n",
    "\n",
    "continous_and_ordinal_vars = [col for col in feature_names if col.startswith(\"n_\")]\n",
    "categorical_vars = [col for col in feature_names if not col.startswith(\"n_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ColumnTransformer(\n",
    "    [\n",
    "        (\"c\", OrdinalEncoder(), categorical_vars),\n",
    "        (\"n\", \"passthrough\", continous_and_ordinal_vars),\n",
    "    ]\n",
    ").fit(data_train_lime)\n",
    "\n",
    "columns = [\n",
    "    col.replace(\"n__\", \"\").replace(\"c__\", \"\") for col in encoder.get_feature_names_out()\n",
    "]\n",
    "X_train_lime = pd.DataFrame(encoder.transform(data_train_lime), columns=columns)\n",
    "X_holdout_lime = pd.DataFrame(encoder.transform(data_holdout_lime), columns=columns)\n",
    "\n",
    "\n",
    "numerical_indices = [\n",
    "    X_train_lime.columns.get_loc(col) for col in continous_and_ordinal_vars\n",
    "]\n",
    "categorical_indices = [X_train_lime.columns.get_loc(col) for col in categorical_vars]\n",
    "\n",
    "categorical_names = {\n",
    "    idx: cat\n",
    "    for idx, cat in zip(categorical_indices, encoder.transformers_[0][1].categories_)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        (\"cat\", OneHotEncoder(), categorical_indices),\n",
    "        (\"num\", \"passthrough\", numerical_indices),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "rf_best_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocess\", preprocessing),\n",
    "        (\"regressor\", rf_model_2.best_estimator_),  # best model\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_pipeline.fit(X_train_lime, data_train.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_fn = lambda x: rf_best_pipeline.predict(x).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "explainer = LimeTabularExplainer(\n",
    "    X_holdout_lime.to_numpy(),\n",
    "    feature_names=X_holdout_lime.columns.tolist(),\n",
    "    categorical_features=categorical_indices,\n",
    "    categorical_names=categorical_names,\n",
    "    mode=\"regression\",\n",
    "    random_state=1237,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = X_holdout_lime.iloc[[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "exp = explainer.explain_instance(\n",
    "    instance.to_numpy()[0],\n",
    "    predict_fn,\n",
    "    num_features=20,\n",
    "    num_samples=1000,\n",
    "    distance_metric=\"euclidean\",\n",
    "    model_regressor=Ridge(\n",
    "        alpha=1, fit_intercept=True, random_state=explainer.random_state\n",
    "    ),\n",
    ")\n",
    "\n",
    "exp.as_pyplot_figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.predicted_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.local_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.intercept[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([i[1] for i in exp.as_list()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactions\n",
    "\n",
    "Look at interactions from `ch14-airbnb-reg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    \"f_room_type*d_familykidfriendly\",\n",
    "    \"f_room_type*f_property_type\",\n",
    "    \"f_property_type*d_airconditioning\",\n",
    "    \"f_property_type*d_cats\",\n",
    "    \"f_property_type*d_dogs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help reveal these interactions we can color by another feature. If we pass the whole explanation tensor to the color argument **the scatter plot will pick the best feature to color by.**\n",
    "\n",
    "Get best proposed interaction by SHAP values for room types. Note that the grey area on the plot corresponds to the distribution of the feature in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4), sharey=True)\n",
    "fig.suptitle(\n",
    "    \"SHAP values and best proposed interaction for room types\",\n",
    "    fontsize=15,\n",
    ")\n",
    "shap.plots.scatter(\n",
    "    shap_values[:, \"f_room_type_Entire home/apt\"],\n",
    "    color=shap_values,\n",
    "    show=False,\n",
    "    cmap=plt.get_cmap(\"viridis_r\"),\n",
    "    ax=ax1,\n",
    ")\n",
    "plt.ylabel(\"SHAP values\")\n",
    "plt.xlabel(\"Entire home/apt\")\n",
    "plt.xlim(-0.2, 1.2)\n",
    "plt.xticks((0, 1), labels=(0, 1))\n",
    "shap.plots.scatter(\n",
    "    shap_values[:, \"f_room_type_Private room\"],\n",
    "    color=shap_values,\n",
    "    show=False,\n",
    "    cmap=plt.get_cmap(\"viridis_r\"),\n",
    "    ax=ax2,\n",
    ")\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"Private room\")\n",
    "plt.xlim(-0.2, 1.2)\n",
    "plt.xticks((0, 1), labels=(0, 1))\n",
    "shap.plots.scatter(\n",
    "    shap_values[:, \"f_room_type_Shared room\"],\n",
    "    color=shap_values,\n",
    "    show=False,\n",
    "    cmap=plt.get_cmap(\"viridis_r\"),\n",
    "    ax=ax3,\n",
    ")\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"Shared room\")\n",
    "plt.xlim(-0.2, 1.2)\n",
    "plt.xticks((0, 1), labels=(0, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turned out, that for the `f_room_type` variable the best interaction (at least based on RF and SHAP) would be the `f_bathroom` which we did not choose in ch14.\n",
    "\n",
    "Let's check for `d_airconditioning`, `d_dogs` and `d_cats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4), sharey=True)\n",
    "fig.suptitle(\n",
    "    \"SHAP values and best proposed interaction for d_airconditioning, d_cats and d_dogs\",\n",
    "    fontsize=15,\n",
    ")\n",
    "shap.plots.scatter(\n",
    "    shap_values[:, \"d_airconditioning\"],\n",
    "    color=shap_values,\n",
    "    show=False,\n",
    "    cmap=plt.get_cmap(\"viridis_r\"),\n",
    "    ax=ax1,\n",
    ")\n",
    "plt.ylabel(\"SHAP values\")\n",
    "plt.xlim(-0.2, 1.2)\n",
    "plt.xticks((0, 1), labels=(0, 1))\n",
    "shap.plots.scatter(\n",
    "    shap_values[:, \"d_cats\"],\n",
    "    color=shap_values,\n",
    "    show=False,\n",
    "    cmap=plt.get_cmap(\"viridis_r\"),\n",
    "    ax=ax2,\n",
    ")\n",
    "plt.ylabel(None)\n",
    "plt.xlim(-0.2, 1.2)\n",
    "plt.xticks((0, 1), labels=(0, 1))\n",
    "shap.plots.scatter(\n",
    "    shap_values[:, \"d_dogs\"],\n",
    "    color=shap_values,\n",
    "    show=False,\n",
    "    cmap=plt.get_cmap(\"viridis_r\"),\n",
    "    ax=ax3,\n",
    ")\n",
    "plt.ylabel(None)\n",
    "plt.xlim(-0.2, 1.2)\n",
    "plt.xticks((0, 1), labels=(0, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution in grey is switched off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4), sharey=True)\n",
    "fig.suptitle(\n",
    "    \"SHAP values and best proposed interaction for d_airconditioning, d_cats and d_dogs\",\n",
    "    fontsize=15,\n",
    ")\n",
    "shap.plots.scatter(\n",
    "    shap_values[:, \"d_airconditioning\"],\n",
    "    color=shap_values,\n",
    "    show=False,\n",
    "    hist=False,\n",
    "    cmap=plt.get_cmap(\"viridis_r\"),\n",
    "    ax=ax1,\n",
    ")\n",
    "plt.ylabel(\"SHAP values\")\n",
    "plt.xlim(-0.2, 1.2)\n",
    "plt.xticks((0, 1), labels=(0, 1))\n",
    "shap.plots.scatter(\n",
    "    shap_values[:, \"d_cats\"],\n",
    "    color=shap_values,\n",
    "    show=False,\n",
    "    hist=False,\n",
    "    cmap=plt.get_cmap(\"viridis_r\"),\n",
    "    ax=ax2,\n",
    ")\n",
    "plt.ylabel(None)\n",
    "plt.xlim(-0.2, 1.2)\n",
    "plt.xticks((0, 1), labels=(0, 1))\n",
    "shap.plots.scatter(\n",
    "    shap_values[:, \"d_dogs\"],\n",
    "    color=shap_values,\n",
    "    show=False,\n",
    "    hist=False,\n",
    "    cmap=plt.get_cmap(\"viridis_r\"),\n",
    "    ax=ax3,\n",
    ")\n",
    "plt.ylabel(None)\n",
    "plt.xlim(-0.2, 1.2)\n",
    "plt.xticks((0, 1), labels=(0, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at a discrete feature, `n_accommodates`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.scatter(\n",
    "    shap_values[:, \"n_accommodates\"], color=shap_values, cmap=plt.get_cmap(\"viridis_r\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART IV\n",
    "### HORSERACE: compare with other models \n",
    "-----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. OLS with dummies for area\n",
    "\n",
    " using model B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = dmatrices(\"price ~ \" + \" + \".join(predictors_2), data_train)\n",
    "\n",
    "ols_model = LinearRegression().fit(X, y)\n",
    "\n",
    "# y_test, X_test = dmatrices(\"price ~ \" + \" + \".join(predictors_2), data_holdout)\n",
    "\n",
    "y_hat = ols_model.predict(X)\n",
    "\n",
    "ols_rmse = root_mean_squared_error(y, y_hat)\n",
    "ols_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_model_coeffs_df = pd.DataFrame(\n",
    "    ols_model.coef_.tolist()[0],\n",
    "    index=X.design_info.column_names,\n",
    "    columns=[\"ols_coefficient\"],\n",
    ").assign(ols_coefficient=lambda x: x.ols_coefficient.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_model_coeffs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  LASSO\n",
    "\n",
    "using extended model w interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter l1_ratio corresponds to alpha in the glmnet R package while alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio = 1 is the lasso penalty. Currently, l1_ratio <= 0.01 is not reliable, unless you supply your own sequence of alpha.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = ElasticNet(l1_ratio=1, normalize=True, fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model_cv = GridSearchCV(\n",
    "    lasso_model,\n",
    "    {\"alpha\": [i / 100 for i in range(1, 26, 1)]},\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = dmatrices(\"price ~ \" + \" + \".join(predictors_E), data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model_cv.fit(X, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    lasso_model_cv.best_estimator_.coef_.tolist(),\n",
    "    index=X.design_info.column_names,\n",
    "    columns=[\"lasso_coefficient\"],\n",
    ").assign(lasso_coefficient=lambda x: x.lasso_coefficient.round(3)).loc[\n",
    "    lambda x: x.lasso_coefficient != 0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso_rmse = (\n",
    "    pd.DataFrame(lasso_model_cv.cv_results_)\n",
    "    .loc[lambda x: x.param_alpha == lasso_model_cv.best_estimator_.alpha]\n",
    "    .mean_test_score.values[0]\n",
    "    * -1\n",
    ")\n",
    "lasso_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. CART model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = dmatrices(\"price ~ \" + \" + \".join(predictors_2), data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_model = DecisionTreeClassifier(random_state=2018, criterion=\"gini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get potential ccp_alpha parameters\n",
    "\n",
    "path = cart_model.cost_complexity_pruning_path(X, y.ravel())\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply random search to select a \"best\" alpha\n",
    "# RandomizedSearchCV does not calculate all potential alphas, just a random subset\n",
    "\n",
    "cart_model_cv = RandomizedSearchCV(\n",
    "    cart_model,\n",
    "    {\"ccp_alpha\": ccp_alphas},\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose=3,\n",
    ")\n",
    "\n",
    "\n",
    "cart_model_cv.fit(X, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_rmse = (\n",
    "    pd.DataFrame(cart_model_cv.cv_results_)\n",
    "    .loc[lambda x: x.param_ccp_alpha == cart_model_cv.best_estimator_.ccp_alpha]\n",
    "    .mean_test_score.values[0]\n",
    "    * -1\n",
    ")\n",
    "cart_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. GBM\n",
    "\n",
    "**NOTE:** These models run for a **very long time** -- needs further investigations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingRegressor(learning_rate=0.1, min_samples_split=20)\n",
    "\n",
    "tune_grid = {\"n_estimators\": [i for i in range(200, 500, 50)], \"max_depth\": [1, 5, 10]}\n",
    "\n",
    "gbm_model_cv = GridSearchCV(\n",
    "    gbm, tune_grid, cv=5, scoring=\"neg_root_mean_squared_error\", verbose=10, n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [col for col in predictors_2 if col.startswith(\"f_\")]\n",
    "numerical_columns = [col for col in predictors_2 if col not in categorical_columns]\n",
    "\n",
    "categorical_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        (\"cat\", categorical_encoder, categorical_columns),\n",
    "        (\"num\", \"passthrough\", numerical_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "gbm_pipe = Pipeline(\n",
    "    [(\"preprocess\", preprocessing), (\"regressor\", gbm_model_cv)], verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_pipe.fit(data_train[predictors_2], data_train.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_rmse = gbm_pipe.steps[-1][1].best_score_ * -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the next will be in final model, loads of tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_broad = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_grid = {\n",
    "    \"n_estimators\": [i for i in range(50, 500, 50)],\n",
    "    \"max_depth\": [1, 5, 10],\n",
    "    \"learning_rate\": [0.02, 0.05, 0.1, 0.15, 0.2],\n",
    "    \"min_samples_split\": [5, 10, 20, 30],\n",
    "}\n",
    "\n",
    "gbm_model_cv_broad = GridSearchCV(\n",
    "    gbm_broad,\n",
    "    tune_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [col for col in predictors_2 if col.startswith(\"f_\")]\n",
    "numerical_columns = [col for col in predictors_2 if col not in categorical_columns]\n",
    "\n",
    "categorical_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        (\"cat\", categorical_encoder, categorical_columns),\n",
    "        (\"num\", \"passthrough\", numerical_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "gbm_pipe_broad = Pipeline(\n",
    "    [(\"preprocess\", preprocessing), (\"regressor\", gbm_model_cv_broad)], verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_pipe_broad.fit(data_train[predictors_2], data_train.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_broad_rmse = gbm_pipe_broad.steps[-1][1].best_score_ * -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 16.3 Predictive performance of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": [\n",
    "            \"Linear regression (OLS)\",\n",
    "            \"Linear regression (LASSO)\",\n",
    "            \"Regression Tree (CART)\",\n",
    "            \"Random forest (basic tuning)\",\n",
    "            \"Random forest (autotuned)\",\n",
    "            \"GBM (basic tuning)\",\n",
    "            \"GBM (broad tuning)\",\n",
    "        ],\n",
    "        \"RMSE\": [\n",
    "            ols_rmse,\n",
    "            lasso_rmse,\n",
    "            cart_rmse,\n",
    "            rf_model_1_rmse,\n",
    "            rf_model_2_rmse,\n",
    "            gbm_rmse,\n",
    "            gbm_broad_rmse,\n",
    "        ],\n",
    "    }\n",
    ").round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
